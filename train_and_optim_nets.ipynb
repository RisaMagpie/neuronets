{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from my_models import (AlexNet, VGG16, ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ch = 3\n",
    "out_ch = 10\n",
    "\n",
    "models_list = [AlexNet, VGG16, ResNet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание папок для логов разых моделей:\n",
    "checkpoint_dir=\"./data/checkpoints/\"\n",
    "\n",
    "for name in models_list:    \n",
    "    if not os.path.isdir(checkpoint_dir+str(name)):\n",
    "        os.makedirs(checkpoint_dir+str(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# исходники: https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data/CIFAR\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, model_name, epoch_num=2,\n",
    "                checkpoint_dir=checkpoint_dir, data_dir=None): \n",
    "    \n",
    "    net = model_name(in_ch, out_ch)\n",
    "    \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "\n",
    "    net.to(device)\n",
    "    \n",
    "    criterion = config[\"losses\"]() # для итерирования разных losses\n",
    "    optimizer = config[\"optimizers_names\"](net.parameters(), lr=config[\"lr\"])\n",
    "    \"\"\"\n",
    "    if checkpoint_dir: \n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir+model_name, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    \"\"\"\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True)\n",
    "\n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name, num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    load_data(data_dir)\n",
    "    \n",
    "    # заменила конфиг\n",
    "    config = {        \n",
    "        \"lr\":tune.grid_search([1e-2, 1e-1]),   \n",
    "        \"batch_size\": tune.grid_search([100, 1000]),\n",
    "        \"optimizers_names\":  tune.grid_search([optim.Adam, optim.SGD]), # ключи словаря\n",
    "        \"losses\": nn.CrossEntropyLoss \n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = JupyterNotebookReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        overwrite = True,\n",
    "        print_intermediate_tables = False,\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"precision\"]) # немного побаловалась, не нашла что еще добавить на посмотреть\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir, model_name=model_name,\n",
    "                checkpoint_dir=checkpoint_dir),\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "    local_dir= checkpoint_dir+str(model_name))\n",
    "    \n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))    \n",
    "\n",
    "    return best_trial   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/503.6 GiB<br>Using AsyncHyperBand: num_stopped=8\n",
       "Bracket: Iter 2.000: None | Iter 1.000: -2.283280366659165<br>Resources requested: 0/80 CPUs, 0/8 GPUs, 0.0/338.38 GiB heap, 0.0/102.78 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /notebooks/sorokina/data/checkpoints/<class 'my_models.ResNet'>/DEFAULT_2020-12-30_10-25-04<br>Number of trials: 8/8 (8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  lr</th><th>optimizers_names               </th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_483fd_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">0.01</td><td>&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;</td><td style=\"text-align: right;\">1.22226</td><td style=\"text-align: right;\">    0.555 </td></tr>\n",
       "<tr><td>DEFAULT_483fd_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">        1000</td><td style=\"text-align: right;\">0.01</td><td>&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;</td><td style=\"text-align: right;\">1.55684</td><td style=\"text-align: right;\">    0.4253</td></tr>\n",
       "<tr><td>DEFAULT_483fd_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">0.1 </td><td>&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;</td><td style=\"text-align: right;\">2.30584</td><td style=\"text-align: right;\">    0.1062</td></tr>\n",
       "<tr><td>DEFAULT_483fd_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">        1000</td><td style=\"text-align: right;\">0.1 </td><td>&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;</td><td style=\"text-align: right;\">2.43262</td><td style=\"text-align: right;\">    0.1088</td></tr>\n",
       "<tr><td>DEFAULT_483fd_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">0.01</td><td>&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;  </td><td style=\"text-align: right;\">2.2455 </td><td style=\"text-align: right;\">    0.1984</td></tr>\n",
       "<tr><td>DEFAULT_483fd_00005</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">        1000</td><td style=\"text-align: right;\">0.01</td><td>&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;  </td><td style=\"text-align: right;\">2.30029</td><td style=\"text-align: right;\">    0.104 </td></tr>\n",
       "<tr><td>DEFAULT_483fd_00006</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">0.1 </td><td>&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;  </td><td style=\"text-align: right;\">1.7792 </td><td style=\"text-align: right;\">    0.3104</td></tr>\n",
       "<tr><td>DEFAULT_483fd_00007</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">        1000</td><td style=\"text-align: right;\">0.1 </td><td>&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;  </td><td style=\"text-align: right;\">2.28716</td><td style=\"text-align: right;\">    0.1461</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-30 10:27:17,866\tINFO tune.py:448 -- Total run time: 133.07 seconds (133.04 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.01, 'batch_size': 100, 'optimizers_names': <class 'torch.optim.adam.Adam'>, 'losses': <class 'torch.nn.modules.loss.CrossEntropyLoss'>}\n",
      "Best trial final validation loss: 1.2222557097673417\n",
      "Best trial final validation accuracy: 0.555\n"
     ]
    }
   ],
   "source": [
    "for model_name in models_list:\n",
    "    best_trial = main(model_name, num_samples=1, max_num_epochs=2, gpus_per_trial=1)\n",
    "    best_trial_conf = best_trial.config\n",
    "    best_trial_conf['path']=best_trial.checkpoint.value\n",
    "    # файлик, который говорит, где лежит чекпоинт нужной модели и какие параметры:\n",
    "\n",
    "    with open(\"./data/best_trials_info/best_trial_dir_{}.txt\".format(str(model_name)), \"w\") as file:        \n",
    "        json.dump(best_trial_conf, file,  default=lambda o: str(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
