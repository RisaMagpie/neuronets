{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUNet configs comparison: from batchflow, from batchflow with fix, mine\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "UNet configs comparison: from batchflow, from batchflow with fix, mine\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from tensorflow import logging\n",
    "# logging.set_verbosity(logging.ERROR)\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import batchflow\n",
    "from batchflow import Pipeline, B, C, V, D\n",
    "from batchflow.opensets import PascalSegmentation\n",
    "from batchflow.research import Research, Option, Domain, Results, PrintLogger, RP, REP, KV\n",
    "from batchflow.models.metrics import Loss\n",
    "from batchflow.models.torch import UNet, EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1#1000\n",
    "N_REPS = 1#10\n",
    "IMAGE_SHAPE = (160, 160)\n",
    "\n",
    "dataset = PascalSegmentation(bar='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_previous_results(res_name):\n",
    "    if os.path.exists(res_name):\n",
    "        shutil.rmtree(res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 22\n",
    "\n",
    "task_config = {\n",
    "    'inputs/targets/classes': num_classes,  \n",
    "    'head/layout': 'c',\n",
    "    'head/filters': num_classes,\n",
    "    'head/kernel_size': 1,\n",
    "    'loss': 'ce',\n",
    "    'optimizer': 'Adam'\n",
    "}\n",
    "\n",
    "# UNet from batchflow\n",
    "UNet_bf = {'inputs': {'targets': {'classes': 22}},\n",
    " 'placeholder_batch_size': 2,\n",
    " 'device': None,\n",
    " 'benchmark': True,\n",
    " 'profile': False,\n",
    " 'microbatch': None,\n",
    " 'sync_frequency': 1,\n",
    " 'optimizer': 'Adam',\n",
    " 'decay': None,\n",
    " 'amp': True,\n",
    " 'sam_rho': 0.0,\n",
    " 'sam_individual_norm': True,\n",
    " 'order': ['initial_block', 'body', 'head'],\n",
    " 'initial_block': {},\n",
    " 'body': {'encoder': {'downsample': {'layout': 'p',\n",
    "    'pool_size': 2,\n",
    "    'pool_strides': 2},\n",
    "   'num_stages': 4,\n",
    "   'order': ['block', 'skip', 'downsampling'],\n",
    "   'blocks': {'base': batchflow.models.torch.blocks.DefaultBlock,\n",
    "    'layout': 'cna cna',\n",
    "    'kernel_size': 3,\n",
    "    'filters': [64, 128, 256, 512]}},\n",
    "  'decoder': {'skip': True,\n",
    "   'num_stages': None,\n",
    "   'factor': None,\n",
    "   'upsample': {'layout': 'tna'},\n",
    "   'combine': {'op': 'concat', 'leading_index': 1},\n",
    "   'order': ['upsampling', 'combine', 'block'],\n",
    "   'blocks': {'base': batchflow.models.torch.blocks.DefaultBlock,\n",
    "    'layout': 'cna cna',\n",
    "    'kernel_size': 3,\n",
    "    'filters': [512, 256, 128, 64]}},\n",
    "  'embedding': {'base': batchflow.models.torch.blocks.DefaultBlock,\n",
    "   'layout': 'cna cna',\n",
    "   'kernel_size': 3,\n",
    "   'filters': 1024}},\n",
    " 'head': {'layout': 'c',\n",
    "  'filters': 22,\n",
    "  'kernel_size': 1,\n",
    "  'target_shape': None,\n",
    "  'classes': 22,\n",
    "  'units': 22},\n",
    " 'common': {'data_format': 'channels_first'},\n",
    " 'predictions': None,\n",
    " 'output': None,\n",
    " 'loss': 'ce'}\n",
    "\n",
    "# fixed UNet from batchflow\n",
    "config_bf_with_fix = UNet_bf.copy()\n",
    "config_bf_with_fix['body/decoder/upsample'] = dict(layout='tna', filters=[512, 256, 128, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_UNet\n",
    "downsample_depth = 4\n",
    "\n",
    "my_config = {\n",
    "    'body/encoder': {\n",
    "        'num_stages': downsample_depth,\n",
    "        'order': ['block', 'skip', 'downsampling']\n",
    "    },    \n",
    "    'body/encoder/blocks': {\n",
    "        'layout': 'cna cna',\n",
    "        'filters': [32*pow(2, i) for i in range(1, downsample_depth+1)]\n",
    "    },\n",
    "    'body/encoder/downsample': {\n",
    "        'layout': 'p'\n",
    "    },    \n",
    "    \n",
    "    'body/embedding': {\n",
    "        'layout': 'cna cna', \n",
    "        'filters': [64*pow(2, downsample_depth), 64*pow(2, downsample_depth)]\n",
    "    },   \n",
    "\n",
    "    'body/decoder': {\n",
    "        'num_stages': downsample_depth,\n",
    "        'order': ['upsampling', 'combine', 'block']\n",
    "    },\n",
    "    'body/decoder/upsample': {\n",
    "        'layout': 'tna',\n",
    "        'filters': [32*pow(2, i) for i in range(downsample_depth, -1, -1)]\n",
    "    },\n",
    "    'body/decoder/combine': {\n",
    "        'op': 'concat'\n",
    "    },\n",
    "    'body/decoder/blocks': {\n",
    "        'layout': 'cna cna',\n",
    "        'filters': [64*pow(2, i-1) for i in range(downsample_depth, -1, -1)]\n",
    "    }\n",
    "}\n",
    "my_config.update(task_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mask(x):\n",
    "    x = np.squeeze(x)\n",
    "    np.place(x, x==255, 21)\n",
    "    return x\n",
    "\n",
    "train_ppl = (dataset.train.p\n",
    "    .init_variable('train_loss', [])\n",
    "    .init_model('dynamic', C('model'), 'model', config=C('config'))\n",
    "    .resize(size=IMAGE_SHAPE, src=['images', 'labels'], dst=['images', 'labels'])\n",
    "    .to_array(channels='first', src=['images', 'labels'], dst=['images', 'labels'])\n",
    "    .process_mask(B('labels'), save_to=B('labels'))\n",
    "    .train_model('model', B('images'), B('labels'),\n",
    "                fetches='loss', save_to=V('train_loss', mode='a'))\n",
    "    .run_later(BATCH_SIZE, shuffle=True, n_epochs=None)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConfigAlias({'model': 'EncoderDecoder', 'config': 'my_config', 'repetition': '0'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configs = [KV(task_config, \"config_bf\"), KV(config_bf_with_fix, \"config_bf_with_fix\"), KV(my_config, \"my_config\")]\n",
    "# domain = Option('model', [UNet, UNet, EncoderDecoder]) @ Option('config', configs)\n",
    "# list(domain.iterator)\n",
    "\n",
    "configs = [KV(my_config, \"my_config\")]\n",
    "domain = Option('model', [EncoderDecoder]) @ Option('config', configs)\n",
    "list(domain.iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research = (Research()\n",
    "#             .init_domain(domain, n_reps=N_REPS)\n",
    "#             .add_pipeline(train_ppl, variables='loss_history', name='train_ppl', logging=True))\n",
    "\n",
    "# res_name='UNet_pascal_research'\n",
    "# clear_previous_results(res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# research.run(n_iters=ITERATIONS, name=res_name, bar=True, workers=1, devices=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = research.load_results().df\n",
    "# results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add test pipeline for getting metrics with param execute last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ppl = (dataset.test.p\n",
    "                .import_model('model', C('import_from'))\n",
    "                .init_variable('metrics')\n",
    "                .init_variable('predictions')\n",
    "                .resize(size=IMAGE_SHAPE, src=['images', 'labels'], dst=['images', 'labels'])\n",
    "                .to_array(channels='first', src=['images', 'labels'], dst=['images', 'labels'])\n",
    "                .process_mask(B('labels'), save_to=B('labels'))                \n",
    "                .predict_model('model', B('images'), fetches='predictions',\n",
    "                               save_to=V('predictions'))\n",
    "                .run_later(BATCH_SIZE, shuffle=False, n_epochs=1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research UNet_pascal_train_test_research is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Domain updated: 0: 100%|██████████| 1/1.0 [00:49<00:00, 49.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.research.research.Research at 0x7f33c0f12668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_EXECUTE_FREQ = 'last'\n",
    "\n",
    "res_name = 'UNet_pascal_train_test_research'\n",
    "clear_previous_results(res_name)\n",
    "\n",
    "research = (Research()\n",
    "            .init_domain(domain, n_reps=N_REPS)\n",
    "            .add_pipeline(train_ppl, variables='train_loss', name='train_ppl')\n",
    "            .add_pipeline(test_ppl, name='test_ppl',\n",
    "                         execute=TEST_EXECUTE_FREQ, run=True, import_from=RP('train_ppl'))\n",
    "#             .get_metrics(pipeline='test_ppl', metrics_var='metrics', metrics_name='accuracy',\n",
    "#                          returns='accuracy', execute=TEST_EXECUTE_FREQ)\n",
    "           )\n",
    "\n",
    "\n",
    "\n",
    "research.run(n_iters=ITERATIONS, name=res_name, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../batchflow/batchflow/research/results.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  intersection = pd.np.arange(start, end)\n",
      "../batchflow/batchflow/research/results.py:111: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  elements_to_load = pd.np.array([pd.np.isin(it, iterations_to_load) for it in iterations])\n",
      "../batchflow/batchflow/research/results.py:115: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  res[variable] = pd.np.array(dumped_file[variable])[elements_to_load]\n",
      "../batchflow/batchflow/research/results.py:133: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  value.extend([pd.np.nan] * (max_len - len(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>iteration</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>model</th>\n",
       "      <th>config</th>\n",
       "      <th>repetition</th>\n",
       "      <th>update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_ppl</td>\n",
       "      <td>[3.1931756]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2790229673</td>\n",
       "      <td>EncoderDecoder</td>\n",
       "      <td>my_config</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   train_loss  accuracy  iteration sample_index           model  \\\n",
       "0  train_ppl  [3.1931756]       NaN        0.0   2790229673  EncoderDecoder   \n",
       "\n",
       "      config  repetition  update  \n",
       "0  my_config           0       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research.load_results().df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
