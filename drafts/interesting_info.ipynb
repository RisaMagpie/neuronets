{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 3, 32, 32]              84\n",
      "       BatchNorm2d-2            [-1, 3, 32, 32]               6\n",
      "              ReLU-3            [-1, 3, 32, 32]               0\n",
      "            Conv2d-4            [-1, 6, 32, 32]             168\n",
      "       BatchNorm2d-5            [-1, 6, 32, 32]              12\n",
      "              ReLU-6            [-1, 6, 32, 32]               0\n",
      "         MaxPool2d-7            [-1, 6, 16, 16]               0\n",
      "            Conv2d-8            [-1, 6, 16, 16]             330\n",
      "       BatchNorm2d-9            [-1, 6, 16, 16]              12\n",
      "             ReLU-10            [-1, 6, 16, 16]               0\n",
      "           Conv2d-11           [-1, 12, 16, 16]             660\n",
      "      BatchNorm2d-12           [-1, 12, 16, 16]              24\n",
      "             ReLU-13           [-1, 12, 16, 16]               0\n",
      "        MaxPool2d-14             [-1, 12, 8, 8]               0\n",
      "           Conv2d-15             [-1, 12, 8, 8]           1,308\n",
      "      BatchNorm2d-16             [-1, 12, 8, 8]              24\n",
      "             ReLU-17             [-1, 12, 8, 8]               0\n",
      "           Conv2d-18             [-1, 24, 8, 8]           2,616\n",
      "      BatchNorm2d-19             [-1, 24, 8, 8]              48\n",
      "             ReLU-20             [-1, 24, 8, 8]               0\n",
      "        MaxPool2d-21             [-1, 24, 4, 4]               0\n",
      "           Conv2d-22             [-1, 24, 4, 4]           5,208\n",
      "      BatchNorm2d-23             [-1, 24, 4, 4]              48\n",
      "             ReLU-24             [-1, 24, 4, 4]               0\n",
      "           Conv2d-25             [-1, 48, 4, 4]          10,416\n",
      "      BatchNorm2d-26             [-1, 48, 4, 4]              96\n",
      "             ReLU-27             [-1, 48, 4, 4]               0\n",
      "        MaxPool2d-28             [-1, 48, 2, 2]               0\n",
      "           Conv2d-29             [-1, 48, 2, 2]          20,784\n",
      "      BatchNorm2d-30             [-1, 48, 2, 2]              96\n",
      "             ReLU-31             [-1, 48, 2, 2]               0\n",
      "           Conv2d-32             [-1, 48, 2, 2]          20,784\n",
      "      BatchNorm2d-33             [-1, 48, 2, 2]              96\n",
      "             ReLU-34             [-1, 48, 2, 2]               0\n",
      "  ConvTranspose2d-35             [-1, 24, 4, 4]           4,632\n",
      "      BatchNorm2d-36             [-1, 24, 4, 4]              48\n",
      "             ReLU-37             [-1, 24, 4, 4]               0\n",
      "           Conv2d-38             [-1, 24, 4, 4]          10,392\n",
      "      BatchNorm2d-39             [-1, 24, 4, 4]              48\n",
      "             ReLU-40             [-1, 24, 4, 4]               0\n",
      "           Conv2d-41             [-1, 24, 4, 4]           5,208\n",
      "      BatchNorm2d-42             [-1, 24, 4, 4]              48\n",
      "             ReLU-43             [-1, 24, 4, 4]               0\n",
      "  ConvTranspose2d-44             [-1, 12, 8, 8]           1,164\n",
      "      BatchNorm2d-45             [-1, 12, 8, 8]              24\n",
      "             ReLU-46             [-1, 12, 8, 8]               0\n",
      "           Conv2d-47             [-1, 12, 8, 8]           2,604\n",
      "      BatchNorm2d-48             [-1, 12, 8, 8]              24\n",
      "             ReLU-49             [-1, 12, 8, 8]               0\n",
      "           Conv2d-50             [-1, 12, 8, 8]           1,308\n",
      "      BatchNorm2d-51             [-1, 12, 8, 8]              24\n",
      "             ReLU-52             [-1, 12, 8, 8]               0\n",
      "  ConvTranspose2d-53            [-1, 6, 16, 16]             294\n",
      "      BatchNorm2d-54            [-1, 6, 16, 16]              12\n",
      "             ReLU-55            [-1, 6, 16, 16]               0\n",
      "           Conv2d-56            [-1, 6, 16, 16]             654\n",
      "      BatchNorm2d-57            [-1, 6, 16, 16]              12\n",
      "             ReLU-58            [-1, 6, 16, 16]               0\n",
      "           Conv2d-59            [-1, 6, 16, 16]             330\n",
      "      BatchNorm2d-60            [-1, 6, 16, 16]              12\n",
      "             ReLU-61            [-1, 6, 16, 16]               0\n",
      "  ConvTranspose2d-62            [-1, 3, 32, 32]              75\n",
      "      BatchNorm2d-63            [-1, 3, 32, 32]               6\n",
      "             ReLU-64            [-1, 3, 32, 32]               0\n",
      "           Conv2d-65            [-1, 3, 32, 32]             165\n",
      "      BatchNorm2d-66            [-1, 3, 32, 32]               6\n",
      "             ReLU-67            [-1, 3, 32, 32]               0\n",
      "           Conv2d-68            [-1, 3, 32, 32]              84\n",
      "      BatchNorm2d-69            [-1, 3, 32, 32]               6\n",
      "             ReLU-70            [-1, 3, 32, 32]               0\n",
      "           Conv2d-71            [-1, 3, 32, 32]              12\n",
      "================================================================\n",
      "Total params: 90,012\n",
      "Trainable params: 90,012\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.85\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 1.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "\n",
    "from models_module import my_models\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "net = my_models.UNet(3, 3)\n",
    "\"\"\"\n",
    "resnet_output_shapes = [64, 128, 256, 512]\n",
    "resnet_layers_depths = [2,2,2,2]\n",
    "net = my_models.ResNet(3, 10, resnet_output_shapes, resnet_layers_depths, True)\n",
    "\"\"\"\n",
    "net.to(\"cuda:0\")\n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential(\n",
    "  (body): Sequential(\n",
    "    (encoder): EncoderModule(\n",
    "      (skip-0): Identity()\n",
    "      (block-0): ConvBlock\n",
    "     \n",
    "       \n",
    "    \n",
    "        \n",
    " \n",
    "    (decoder): DecoderModule(\n",
    "      (upsample-0): Upsample(\n",
    "        (layer): ConvBlock\n",
    "        layout=tna\n",
    "          Layer 0,  letter \"t\": (None, 48, 2, 2) -> (None, 24, 4, 4)\n",
    "          Layer 1,  letter \"n\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 2,  letter \"a\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          \n",
    "      )\n",
    "      (combine-0): Combine(\n",
    "        op=concat,\n",
    "        leading_idx=1,\n",
    "        input_shapes=[[(2, 24, 4, 4), (2, 24, 4, 4)]],\n",
    "        resized_shapes=[[(2, 24, 4, 4), (2, 24, 4, 4)]],\n",
    "        output_shape=(2, 48, 4, 4)\n",
    "      )\n",
    "      (block-0): ConvBlock\n",
    "      DefaultBlock\n",
    "        layout=cnacna\n",
    "          Layer 0,  letter \"c\": (None, 48, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 1,  letter \"n\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 2,  letter \"a\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 3,  letter \"c\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 4,  letter \"n\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          Layer 5,  letter \"a\": (None, 24, 4, 4) -> (None, 24, 4, 4)\n",
    "          \n",
    "      (upsample-1): Upsample(\n",
    "        (layer): ConvBlock\n",
    "        layout=tna\n",
    "          Layer 0,  letter \"t\": (None, 24, 4, 4) -> (None, 12, 8, 8)\n",
    "          Layer 1,  letter \"n\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 2,  letter \"a\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          \n",
    "      )\n",
    "      (combine-1): Combine(\n",
    "        op=concat,\n",
    "        leading_idx=1,\n",
    "        input_shapes=[[(2, 12, 8, 8), (2, 12, 8, 8)]],\n",
    "        resized_shapes=[[(2, 12, 8, 8), (2, 12, 8, 8)]],\n",
    "        output_shape=(2, 24, 8, 8)\n",
    "      )\n",
    "      (block-1): ConvBlock\n",
    "      DefaultBlock\n",
    "        layout=cnacna\n",
    "          Layer 0,  letter \"c\": (None, 24, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 1,  letter \"n\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 2,  letter \"a\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 3,  letter \"c\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 4,  letter \"n\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          Layer 5,  letter \"a\": (None, 12, 8, 8) -> (None, 12, 8, 8)\n",
    "          \n",
    "      (upsample-2): Upsample(\n",
    "        (layer): ConvBlock\n",
    "        layout=tna\n",
    "          Layer 0,  letter \"t\": (None, 12, 8, 8) -> (None, 6, 16, 16)\n",
    "          Layer 1,  letter \"n\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 2,  letter \"a\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          \n",
    "      )\n",
    "      (combine-2): Combine(\n",
    "        op=concat,\n",
    "        leading_idx=1,\n",
    "        input_shapes=[[(2, 6, 16, 16), (2, 6, 16, 16)]],\n",
    "        resized_shapes=[[(2, 6, 16, 16), (2, 6, 16, 16)]],\n",
    "        output_shape=(2, 12, 16, 16)\n",
    "      )\n",
    "      (block-2): ConvBlock\n",
    "      DefaultBlock\n",
    "        layout=cnacna\n",
    "          Layer 0,  letter \"c\": (None, 12, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 1,  letter \"n\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 2,  letter \"a\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 3,  letter \"c\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 4,  letter \"n\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          Layer 5,  letter \"a\": (None, 6, 16, 16) -> (None, 6, 16, 16)\n",
    "          \n",
    "      (upsample-3): Upsample(\n",
    "        (layer): ConvBlock\n",
    "        layout=tna\n",
    "          Layer 0,  letter \"t\": (None, 6, 16, 16) -> (None, 3, 32, 32)\n",
    "          Layer 1,  letter \"n\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 2,  letter \"a\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          \n",
    "      )\n",
    "      (combine-3): Combine(\n",
    "        op=concat,\n",
    "        leading_idx=1,\n",
    "        input_shapes=[[(2, 3, 32, 32), (2, 3, 32, 32)]],\n",
    "        resized_shapes=[[(2, 3, 32, 32), (2, 3, 32, 32)]],\n",
    "        output_shape=(2, 6, 32, 32)\n",
    "      )\n",
    "      (block-3): ConvBlock\n",
    "      DefaultBlock\n",
    "        layout=cnacna\n",
    "          Layer 0,  letter \"c\": (None, 6, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 1,  letter \"n\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 2,  letter \"a\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 3,  letter \"c\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 4,  letter \"n\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          Layer 5,  letter \"a\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "          \n",
    "    )\n",
    "  )\n",
    "  (head): Sequential(\n",
    "    (0): ConvBlock\n",
    "    layout=ca\n",
    "      Layer 0,  letter \"c\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "      Layer 1,  letter \"a\": (None, 3, 32, 32) -> (None, 3, 32, 32)\n",
    "      \n",
    "  )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
