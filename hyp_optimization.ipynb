{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from fastai.vision.all import URLs\n",
    "from train_module import training_functions\n",
    "from models_module import my_models\n",
    "\n",
    "LOG_PATH = \"./data/optimizing_logs/\"\n",
    "GRAPH_PATH = \"./data/graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 10\n",
    "device = \"cuda:0\"\n",
    "\n",
    "batch_size = 10\n",
    "epoch_num = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [nn.CrossEntropyLoss]\n",
    "learning_rates = [1e-4,  1e-5]\n",
    "optimizers = [optim.Adam]#, optim.SGD]\n",
    "linear_layers_shapes = [[300,200], [300,300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = URLs.IMAGENETTE_160\n",
    "trainloader, valloader = training_functions.prepare_train_and_val_dls(path, batch_size, size=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 1/4:\n",
      "    Loss: <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
      " Learning_rate: 0.0001,\n",
      "    Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      "),\n",
      " linear_layers_out_size:[300, 200, 10]\n",
      "Time: 1136.4309344291687\n",
      "Config 2/4:\n",
      "    Loss: <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
      " Learning_rate: 0.0001,\n",
      "    Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      "),\n",
      " linear_layers_out_size:[300, 300, 10]\n",
      "Time: 1160.5978634357452\n",
      "Config 3/4:\n",
      "    Loss: <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
      " Learning_rate: 1e-05,\n",
      "    Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-05\n",
      "    weight_decay: 0\n",
      "),\n",
      " linear_layers_out_size:[300, 200, 10, 10]\n",
      "Time: 1168.567194700241\n",
      "Config 4/4:\n",
      "    Loss: <class 'torch.nn.modules.loss.CrossEntropyLoss'>,\n",
      " Learning_rate: 1e-05,\n",
      "    Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-05\n",
      "    weight_decay: 0\n",
      "),\n",
      " linear_layers_out_size:[300, 300, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "for iteration_number, (loss, learning_rate, optimizer, lin_shapes) in enumerate(\n",
    "    itertools.product(train_losses, learning_rates, optimizers, linear_layers_shapes)\n",
    "):\n",
    "    lin_shapes.append(out_channels)\n",
    "    net = my_models.VGG(in_channels = in_channels, \n",
    "                        out_channels = out_channels,\n",
    "                        conv_blocks_out_size = [64,128,256,512,512],\n",
    "                        conv_blocks_amounts = [2,2,2,2,2],\n",
    "                        linear_layers_out_size = lin_shapes.copy())\n",
    "    net.to(device)\n",
    "    \n",
    "    loss = loss()\n",
    "    optimizer = optimizer(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    iter_amount = len(train_losses)*len(learning_rates)*len(optimizers)*len(linear_layers_shapes)\n",
    "    \n",
    "    info_to_show = f\"\"\"Config {iteration_number+1}/{iter_amount}:\n",
    "    Loss: {loss.__class__},\\n Learning_rate: {learning_rate},\n",
    "    Optimizer: {optimizer},\\n linear_layers_out_size:{lin_shapes}\"\"\"\n",
    "    print(info_to_show)\n",
    "        \n",
    "    start = time.time()\n",
    "    net, optimization_history = training_functions.train(net, optimizer,\n",
    "                                                         loss, epoch_num, \n",
    "                                                         trainloader, valloader, \n",
    "                                                         device, \n",
    "                                                         GRAPH_PATH+f\"training_config_{iteration_number}_info.jpg\")\n",
    "\n",
    "    validation_info.append([iteration_number+1, \n",
    "                            loss, learning_rate, optimizer, lin_shapes,\n",
    "                            min(optimization_history[\"val losses\"]), \n",
    "                            max(optimization_history[\"val accuracy\"]), \n",
    "                            min(optimization_history[\"train losses\"]), \n",
    "                            max(optimization_history[\"train accuracy\"])])\n",
    "    print(f\"Time: {time.time()-start}\")\n",
    "    with torch.no_grad():\n",
    "        torch.save({\"model_instance\" : net,\n",
    "                    \"loss function\" : loss,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": optimizer,\n",
    "                   \"lin_shapes\": lin_shapes},\n",
    "                   LOG_PATH+f\"model_{iteration_number+1}\", \n",
    "                   pickle_module=dill)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(validation_info, \n",
    "                   columns=[\"model_number\", \"loss\", \"learning_rate\", \"optimizer\", \"lin_shapes\",\n",
    "                            \"best_val_loss\", \"best_val_acc\", \"best_train_loss\", \"best_train_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[res[\"best_val_acc\"]==max(res[\"best_val_acc\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
