{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "LOG_PATH = \"./data/profile_info/\"\n",
    "DATA_DIR = './data/MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALED_SHAPE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, batch_size, transform):\n",
    "    trainset = torchvision.datasets.MNIST(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "scaled_transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(SCALED_SHAPE),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "default_train_loader, default_test_loader = load_data(data_dir=DATA_DIR, batch_size=batch_size, transform=default_transform)\n",
    "scaled_train_loader, scaled_test_loader = load_data(data_dir=DATA_DIR, batch_size=batch_size, transform=scaled_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "device = \"cuda:0\"\n",
    "\n",
    "#train_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "batch_size = 256\n",
    "epoch_num = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion, epoch_num, default_train_data, scaled_train_data, device):\n",
    "    \"\"\"Neural network training process.\n",
    "    \n",
    "    \"\"\"\n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "        for ((default_data, _), (scaled_data, _)) in zip(default_train_data, scaled_train_data):\n",
    "            inputs = default_data.to(device)\n",
    "            masks = scaled_data.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, channels_list):\n",
    "        super().__init__()\n",
    "        channels_list.insert(0, 1)\n",
    "        self.downsample = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for in_ch, out_ch in zip(channels_list[:-1], channels_list[1:])\n",
    "        ])\n",
    "        self.upsample = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for in_ch, out_ch in zip(channels_list[:-1:-1], channels_list[1::-1])\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        for layer in self.downsample:\n",
    "            tensor = layer(tensor)\n",
    "            tensor = F.max_pool2d(tensor, kernel_size=2) \n",
    "        for layer in self.upsample:\n",
    "            tensor = layer(tensor)       \n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([8, 16, 32])\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4d 10h 25min 43s, sys: 28min 58s, total: 4d 10h 54min 42s\n",
      "Wall time: 5h 24min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "net = train(\n",
    "    net, optimizer, train_loss, epoch_num, trainset, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 15s, sys: 4.14 s, total: 20min 19s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for data, _ in testset:\n",
    "    inputs = data.to(device)\n",
    "    _ = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
