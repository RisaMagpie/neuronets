{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchflow import Pipeline, D, B, V, C, R, P\n",
    "from batchflow.opensets import Imagenette160\n",
    "from batchflow.models.torch import UNet\n",
    "from batchflow import GPUMemoryMonitor\n",
    "from fastai.vision.all import URLs\n",
    "from batchflow.models.torch import EncoderDecoder\n",
    "import torch\n",
    "from train_module import training_functions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:05<00:05,  5.57s/it]\n"
     ]
    }
   ],
   "source": [
    "init_batch_size = 16\n",
    "epochs_num = 25\n",
    "\n",
    "dataset = Imagenette160(bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 4\n",
    "\n",
    "model_config = dict(model = UNet)\n",
    "model_config['device'] = f'cuda:{device_id}'\n",
    "model_config['loss'] = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (dataset.train.p\n",
    "                .crop(shape=(160, 160), origin='center')\n",
    "                .init_variable('loss_history', [])\n",
    "                .to_array(channels='first', dtype=np.float32)\n",
    "                .multiply(1./255)\n",
    "                .init_model('dynamic', UNet, 'unet',\n",
    "                            config=model_config)\n",
    "                .train_model('unet', B.images, B.images, \n",
    "                             fetches='loss', save_to=V('loss_history', mode='a'), use_lock=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a858766c70c4fe98dda36e9b85bb1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/sorokina/batchflow/batchflow/models/torch/unet.py:104: UserWarning: 'decoder/upsample/filters' are not set and can be inconsistent with 'decoder/blocks/filters'! Please revise your model's config. In future, upsample filters can be made to match decoder block's filters by default.\n",
      "  \"In future, upsample filters can be made to match decoder block's filters by default.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ed361d0f564f559509189b4ac2db83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with GPUMemoryMonitor(gpu_list=[device_id]) as monitor:\n",
    "    torch.cuda.empty_cache()\n",
    "    train_pipeline.run(init_batch_size, n_iters=epochs_num, bar='n')\n",
    "first_run_memory = np.max(monitor.data)\n",
    "with GPUMemoryMonitor(gpu_list=[device_id]) as monitor:\n",
    "    torch.cuda.empty_cache()\n",
    "    train_pipeline.run(2*init_batch_size, n_iters=epochs_num, bar='n')\n",
    "second_run_memory = np.max(monitor.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happend:\n",
    "\n",
    "***run_memory = model_size + item_size * batch_size***\n",
    "\n",
    "We set: ***init_batch_size = 16***\n",
    " \n",
    "\n",
    "So, we have two equations:\n",
    "\n",
    "***first_run_memory = model_size + init_batch_size * item_size***\n",
    "\n",
    "***second_run_memory = model_size + 2 * init_batch_size * item_size***\n",
    "\n",
    "We can get:\n",
    "\n",
    "***item_size * init_batch_size = second_run_memory - first_run_memory***\n",
    "\n",
    "***model_size = first_run_memory - item_size * init_batch_size = 2 * first_run_memory - second_run_memory***\n",
    "\n",
    "We want to know max_batch_size if we have total_memory amount of GPU memory.\n",
    "\n",
    "***max_batch_size = (total_memory - model_size)/item_size***\n",
    "\n",
    "It is equal to:\n",
    "\n",
    "***max_batch_size = (total_memory - model_size)/((second_run_memory - first_run_memory)/init_batch_size)*** \n",
    "\n",
    "where init_batch_size=16\n",
    "\n",
    "or:\n",
    "\n",
    "***max_batch_size = init_batch_size * (total_memory - model_size)/(second_run_memory - first_run_memory)*** \n",
    "\n",
    "\n",
    "Memory is measured as a percentage, so ***total_memory = 100*** %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batch_size = init_batch_size * (100 - 2 * first_run_memory + second_run_memory)/(second_run_memory - first_run_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.1768149882904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
